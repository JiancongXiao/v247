---
title: Faster Sampling without Isoperimetry via Diffusion-based Monte Carlo
section: Original Papers
abstract: " To sample from a general target distribution $p_*\\propto e^{-f_*}$ beyond
  the isoperimetric condition, Huang et al. (2023) proposed to perform sampling through
  reverse diffusion, giving rise to Diffusion-based  Monte Carlo (DMC). Specifically,
  \ DMC follows the reverse SDE of a diffusion process that transforms the target
  distribution to the standard Gaussian, utilizing a non-parametric score estimation.
  However, the original DMC algorithm encountered high gradient complexity, resulting
  in an exponential dependency on the error tolerance $\\epsilon$ of the obtained
  samples. In this paper, we demonstrate that the high complexity of the original
  DMC algorithm originates from its redundant design of score estimation, and proposed
  a more efficient DMC algorithm, called RS-DMC, based on a novel recursive score
  estimation method. In particular, we first divide the entire diffusion process into
  multiple segments and then formulate the score estimation step (at any time step)
  as a series of interconnected mean estimation and sampling subproblems accordingly,
  which are correlated in a recursive manner. Importantly, we show that with a proper
  design of the segment decomposition, all sampling subproblems will only need to
  tackle a strongly log-concave distribution, which can be very efficient to solve
  using the standard sampler (e.g., Langevin Monte Carlo) with a provably rapid convergence
  rate. As a result, we prove that the gradient complexity of RS-DMC exhibits merely
  a quasi-polynomial dependency on $\\epsilon$. This finding is highly unexpected
  as it substantially enhances the prevailing belief of the necessity for exponential
  gradient complexity in all prior works such as Huang et al. (2023). Under commonly
  used dissipative conditions, our algorithm is provably much faster than the popular
  Langevin-based algorithms. Our algorithm design and theoretical framework illuminate
  a novel direction for addressing sampling problems, which could be of broader applicability
  in the community. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: huang24a
month: 0
tex_title: Faster Sampling without Isoperimetry via Diffusion-based Monte Carlo
firstpage: 2438
lastpage: 2493
page: 2438-2493
order: 2438
cycles: false
bibtex_author: Huang, Xunpeng and Zou, Difan and Dong, Hanze and Ma, Yi-An and Zhang,
  Tong
author:
- given: Xunpeng
  family: Huang
- given: Difan
  family: Zou
- given: Hanze
  family: Dong
- given: Yi-An
  family: Ma
- given: Tong
  family: Zhang
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/huang24a/huang24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
