---
title: Regularization and Optimal Multiclass Learning
section: Original Papers
abstract: 'The quintessential learning algorithm of empirical risk minimization (ERM)
  is known to fail in various settings for which uniform convergence does not characterize
  learning. Relatedly, the practice of machine learning is rife with considerably
  richer algorithmic techniques, perhaps the most notable of which is regularization.
  Nevertheless, no such technique or principle has broken away from the pack to characterize
  optimal learning in these more general settings. The purpose of this work is to
  precisely characterize the role of regularization in perhaps the simplest setting
  for which ERM fails: multiclass learning with arbitrary label sets. Using one-inclusion
  graphs (OIGs), we exhibit optimal learning algorithms that dovetail with tried-and-true
  algorithmic principles: Occam’s Razor as embodied by structural risk minimization
  (SRM), the principle of maximum entropy, and Bayesian inference. We also extract
  from OIGs a combinatorial sequence we term the Hall complexity, which is the first
  to characterize a problem’s transductive error rate exactly. Lastly, we introduce
  a generalization of OIGs and the transductive learning setting to the agnostic case,
  where we show that optimal orientations of Hamming graphs – judged using nodes’
  outdegrees minus a system of node-dependent credits – characterize optimal learners
  exactly. We demonstrate that an agnostic version of the Hall complexity again characterizes
  error rates exactly, and exhibit an optimal learner using maximum entropy programs.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: asilis24a
month: 0
tex_title: Regularization and Optimal Multiclass Learning
firstpage: 260
lastpage: 310
page: 260-310
order: 260
cycles: false
bibtex_author: Asilis, Julian and Devic, Siddartha and Dughmi, Shaddin and Sharan,
  Vatsal and Teng, Shang-Hua
author:
- given: Julian
  family: Asilis
- given: Siddartha
  family: Devic
- given: Shaddin
  family: Dughmi
- given: Vatsal
  family: Sharan
- given: Shang-Hua
  family: Teng
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/asilis24a/asilis24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
