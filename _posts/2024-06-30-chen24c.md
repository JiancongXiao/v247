---
title: Near-Optimal Learning and Planning in Separated Latent MDPs
section: Original Papers
abstract: We study computational and statistical aspects of learning  Latent Markov
  Decision Processes (LMDPs). In this model, the learner interacts with an MDP drawn
  at the beginning of each epoch from an unknown mixture of MDPs. To sidestep known
  impossibility results, we consider several notions of $\delta$-separation of the
  constituent MDPs. The main thrust of this paper is in establishing a nearly-sharp
  \textit{statistical threshold} for the horizon length necessary for efficient learning.
  On the computational side, we show that under a weaker assumption of separability
  under the optimal policy, there is a quasi-polynomial algorithm with time complexity
  scaling in terms of the statistical threshold. We further show a near-matching time
  complexity lower bound under the exponential time hypothesis.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24c
month: 0
tex_title: Near-Optimal Learning and Planning in Separated Latent MDPs
firstpage: 995
lastpage: 1067
page: 995-1067
order: 995
cycles: false
bibtex_author: Chen, Fan and Daskalakis, Constantinos and Golowich, Noah and Rakhlin,
  Alexander
author:
- given: Fan
  family: Chen
- given: Constantinos
  family: Daskalakis
- given: Noah
  family: Golowich
- given: Alexander
  family: Rakhlin
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/chen24c/chen24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
