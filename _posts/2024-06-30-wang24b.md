---
title: Nonlinear spiked covariance matrices and signal propagation in deep neural
  networks
section: Original Papers
abstract: Many recent works have studied the eigenvalue spectrum of the Conjugate
  Kernel (CK) defined by the nonlinear feature map of a feedforward neural network.
  However, existing results only establish weak convergence of the empirical eigenvalue
  distribution, and fall short of providing precise quantitative characterizations
  of the “spike” eigenvalues and eigenvectors that often capture the low-dimensional
  signal structure of the learning problem. In this work, we characterize these signal
  eigenvalues and eigenvectors for a nonlinear version of the spiked covariance model,
  including the CK as a special case. Using this general result, we give a quantitative
  description of how spiked eigenstructure in the input data propagates through the
  hidden layers of a neural network with random weights. As a second application,
  we study a simple regime of representation learning where the weight matrix develops
  a rank-one signal component over training and characterize the alignment of the
  target function with the spike eigenvector of the CK on test data.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang24b
month: 0
tex_title: Nonlinear spiked covariance matrices and signal propagation in deep neural
  networks
firstpage: 4891
lastpage: 4957
page: 4891-4957
order: 4891
cycles: false
bibtex_author: Wang, Zhichao and Wu, Denny and Fan, Zhou
author:
- given: Zhichao
  family: Wang
- given: Denny
  family: Wu
- given: Zhou
  family: Fan
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/wang24b/wang24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
