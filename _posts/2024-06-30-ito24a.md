---
title: 'Adaptive Learning Rate for Follow-the-Regularized-Leader: Competitive Analysis
  and Best-of-Both-Worlds'
section: Original Papers
abstract: Follow-The-Regularized-Leader (FTRL) is known as an effective and versatile
  approach in online learning, where appropriate choice of the learning rate is crucial
  for smaller regret. To this end, we formulate the problem of adjusting FTRLâ€™s learning
  rate as a sequential decision-making problem and introduce the framework of competitive
  analysis. We establish a lower bound for the competitive ratio and propose update
  rules for the learning rate that achieves an upper bound within a constant factor
  of this lower bound. Specifically, we illustrate that the optimal competitive ratio
  is characterized by the (approximate) monotonicity of components of the penalty
  term, showing that a constant competitive ratio is achievable if the components
  of the penalty term form a monotone non-increasing sequence, and derive a tight
  competitive ratio when penalty terms are $\xi$-approximately monotone non-increasing.
  Our proposed update rule, referred to as \textit{stability-penalty matching}, also
  facilitates the construction of Best-Of-Both-Worlds (BOBW) algorithms for stochastic
  and adversarial environments. In these environments our results contribute to achieving
  tighter regret bound and broaden the applicability of algorithms for various settings
  such as multi-armed bandits, graph bandits, linear bandits, and contextual bandits.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ito24a
month: 0
tex_title: 'Adaptive Learning Rate for Follow-the-Regularized-Leader: Competitive
  Analysis and Best-of-Both-Worlds'
firstpage: 2522
lastpage: 2563
page: 2522-2563
order: 2522
cycles: false
bibtex_author: Ito, Shinji and Tsuchiya, Taira and Honda, Junya
author:
- given: Shinji
  family: Ito
- given: Taira
  family: Tsuchiya
- given: Junya
  family: Honda
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/ito24a/ito24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
