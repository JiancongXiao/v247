---
title: Optimistic Information Directed Sampling
section: Original Papers
abstract: We study the problem of online learning in contextual bandit problems where
  the loss function is assumed to belong to a known parametric function class. We
  propose a new analytic framework for this setting that bridges the Bayesian theory
  of information-directed sampling due to Russo and Van Roy (2018) and the worst-case
  theory of Foster et al. (2021) based on the decision-estimation coefficient. Drawing
  from both lines of work, we propose a algorithmic template called Optimistic Information-Directed
  Sampling and show that it can achieve instance-dependent regret guarantees similar
  to the ones achievable by the classic Bayesian IDS method, but with the major advantage
  of not requiring any Bayesian assumptions. The key technical innovation of our analysis
  is introducing an optimistic surrogate model for the regret and using it to define
  a frequentist version of the Information Ratio of Russo and Van Roy (2018), and
  a less conservative version of the Decision Estimation Coefficient of Foster et
  al. (2021).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: neu24a
month: 0
tex_title: Optimistic Information Directed Sampling
firstpage: 3970
lastpage: 4006
page: 3970-4006
order: 3970
cycles: false
bibtex_author: Neu, Gergely and Papini, Matteo and Schwartz, Ludovic
author:
- given: Gergely
  family: Neu
- given: Matteo
  family: Papini
- given: Ludovic
  family: Schwartz
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/neu24a/neu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
