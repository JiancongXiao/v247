---
title: Settling the sample complexity of online reinforcement learning
section: Original Papers
abstract: 'A central issue lying at the heart of online reinforcement learning (RL)
  is data efficiency.  While a number of recent works achieved asymptotically minimal
  regret in online RL, the optimality of these results is only guaranteed in a “large-sample”
  regime, imposing enormous burn-in cost in order for their algorithms to operate
  optimally. How to achieve minimax-optimal regret without incurring any burn-in cost
  has been an open problem in RL theory.   We settle this problem for finite-horizon
  inhomogeneous Markov decision processes. Specifically, we prove that a modified
  version of MVP (Monotonic Value Propagation), an optimistic model-based algorithm
  proposed by Zhang et al., achieves a regret on the order of $$\min\big\{  \sqrt{SAH^3K},
  \,HK \big\},$$ where $S$ is the number of states, $A$ is the number of actions,
  $H$ is the horizon length, and $K$ is the total number of episodes. This regret
  matches the minimax lower bound for the entire range of sample size K, essentially
  eliminating any burn-in requirement. It also translates to a PAC sample complexity
  (i.e., the number of episodes needed to yield $\varepsilon$-accuracy) of $\frac{SAH^3}{\varepsilon^2}$
  up to log factor, which is minimax-optimal for the full epsilon-range. Further,
  we extend our theory to unveil the influences of problem-dependent quantities like
  the optimal value/cost and certain variances. The key technical innovation lies
  in a novel analysis paradigm to decouple complicated statistical dependency — a
  long-standing challenge facing the analysis of online RL in the sample-hungry regime.   '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang24a
month: 0
tex_title: Settling the sample complexity of online reinforcement learning
firstpage: 5213
lastpage: 5219
page: 5213-5219
order: 5213
cycles: false
bibtex_author: Zhang, Zihan and Chen, Yuxin and Lee, Jason D and Du, Simon S
author:
- given: Zihan
  family: Zhang
- given: Yuxin
  family: Chen
- given: Jason D
  family: Lee
- given: Simon S
  family: Du
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/zhang24a/zhang24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
