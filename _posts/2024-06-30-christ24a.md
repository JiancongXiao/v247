---
title: Undetectable Watermarks for Language Models
section: Original Papers
abstract: 'Recent advances in the capabilities of large language models such as GPT-4
  have spurred increasing concern about our ability to detect AI-generated text.  Prior
  works have suggested methods of embedding watermarks in model outputs, by *noticeably*
  altering the output distribution. We ask: Is it possible to introduce a watermark
  without incurring *any detectable* change to the output distribution? To this end,
  we introduce a cryptographically-inspired notion of undetectable watermarks for
  language models.  That is, watermarks can be detected only with the knowledge of
  a secret key; without the secret key, it is computationally intractable to distinguish
  watermarked outputs from those of the original model. In particular, it is impossible
  for a user to observe any degradation in the quality of the text. Crucially, watermarks
  remain undetectable even when the user is allowed to adaptively query the model
  with arbitrarily chosen prompts. We construct undetectable watermarks based on the
  existence of one-way functions, a standard assumption in cryptography.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: christ24a
month: 0
tex_title: Undetectable Watermarks for Language Models
firstpage: 1125
lastpage: 1139
page: 1125-1139
order: 1125
cycles: false
bibtex_author: Christ, Miranda and Gunn, Sam and Zamir, Or
author:
- given: Miranda
  family: Christ
- given: Sam
  family: Gunn
- given: Or
  family: Zamir
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/christ24a/christ24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
