---
title: Smaller Confidence Intervals From IPW Estimators via Data-Dependent Coarsening
  (Extended Abstract)
section: Original Papers
abstract: 'Inverse propensity-score weighted (IPW) estimators are prevalent in causal
  inference for estimating average treatment effects in observational studies. Under
  unconfoundedness, given accurate propensity scores and $n$ samples, the size of
  confidence intervals of IPW estimators scales down with $n$, and, several of their
  variants improve the rate of scaling. However, neither IPW estimators nor their
  variants are robust to inaccuracies: even if a single covariate has an $\epsilon>0$
  additive error in the propensity score, the size of confidence intervals of these
  estimators can increase arbitrarily. Moreover, even without errors, the rate with
  which the confidence intervals of these estimators go to zero with $n$ can be arbitrarily
  slow in the presence of extreme propensity scores (those close to 0 or 1). We introduce
  a family of Coarse IPW (CIPW) estimators that captures existing IPW estimators and
  their variants. Each CIPW estimator is an IPW estimator on a coarsened covariate
  space, where certain covariates are merged. Under mild assumptions, e.g., Lipschitzness
  in expected outcomes and sparsity of extreme propensity scores, we give an efficient
  algorithm to find a robust estimator: given $\epsilon$-inaccurate propensity scores
  and $n$ samples, its confidence interval size scales with $\epsilon+(1/\sqrt{n})$.
  In contrast, under the same assumptions, existing estimatorsâ€™ confidence interval
  sizes are $\Omega(1)$ irrespective of $\epsilon$ and $n$. Crucially, our estimator
  is data-dependent and we show that no data-independent CIPW estimator can be robust
  to inaccuracies. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kalavasis24a
month: 0
tex_title: Smaller Confidence Intervals From IPW Estimators via Data-Dependent Coarsening
  (Extended Abstract)
firstpage: 2767
lastpage: 2767
page: 2767-2767
order: 2767
cycles: false
bibtex_author: Kalavasis, Alkis and Mehrotra, Anay and Zampetakis, Manolis
author:
- given: Alkis
  family: Kalavasis
- given: Anay
  family: Mehrotra
- given: Manolis
  family: Zampetakis
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/kalavasis24a/kalavasis24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
