---
title: Minimax-optimal reward-agnostic exploration in reinforcement learning
section: Original Papers
abstract: 'This paper studies reward-agnostic exploration in reinforcement learning
  (RL) — a scenario where the learner is unware of the reward functions during the
  exploration stage — and designs an algorithm that improves over the state of the
  art. More precisely, consider a finite-horizon inhomogeneous Markov decision process
  with $S$ states, $A$ actions, and horizon length $H$, and suppose that there are
  no more than a polynomial number of given reward functions of interest. By collecting
  an order of $\frac{SAH^3}{\varepsilon^2}$ sample episodes (up to log factor) without
  guidance of the reward information, our algorithm is able to find $\varepsilon$-optimal
  policies for all these reward functions, provided that $\varepsilon$ is sufficiently
  small. This forms the first reward-agnostic exploration scheme in this context that
  achieves provable minimax optimality. Furthermore, once the sample size exceeds
  $\frac{S^2AH^3}{\varepsilon^2}$ episodes (up to log factor), our algorithm is able
  to yield $\varepsilon$ accuracy for arbitrarily many reward functions (even when
  they are adversarially designed),  a task commonly dubbed as “reward-free exploration.”
  The novelty of our algorithm design draws on insights from offline RL: the exploration
  scheme attempts to maximize a critical reward-agnostic quantity that dictates the
  performance of offline RL, while the policy learning paradigm leverages ideas from
  sample-optimal offline RL paradigms.  '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24a
month: 0
tex_title: Minimax-optimal reward-agnostic exploration in reinforcement learning
firstpage: 3431
lastpage: 3436
page: 3431-3436
order: 3431
cycles: false
bibtex_author: Li, Gen and Yan, Yuling and Chen, Yuxin and Fan, Jianqing
author:
- given: Gen
  family: Li
- given: Yuling
  family: Yan
- given: Yuxin
  family: Chen
- given: Jianqing
  family: Fan
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/li24a/li24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
