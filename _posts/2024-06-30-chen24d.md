---
title: Scale-free Adversarial Reinforcement Learning
section: Original Papers
abstract: This paper initiates the study of scale-free learning in Markov Decision
  Processes (MDPs), where the scale of rewards/losses is unknown to the learner. We
  design a generic algorithmic framework, \underline{S}cale \underline{C}lipping \underline{B}ound
  (\texttt{SCB}), and instantiate this framework in both the adversarial Multi-armed
  Bandit (MAB) setting and the adversarial MDP setting. Through this framework, we
  achieve the first minimax optimal expected regret bound and the first high-probability
  regret bound in scale-free adversarial MABs, resolving an open problem raised in
  \cite{hadiji2020adaptation}. On adversarial MDPs, our framework also give birth
  to the first scale-free RL algorithm with a $\tilde{\mathcal{O}}(\sqrt{T})$ high-probability
  regret guarantee.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24d
month: 0
tex_title: Scale-free Adversarial Reinforcement Learning
firstpage: 1068
lastpage: 1101
page: 1068-1101
order: 1068
cycles: false
bibtex_author: Chen, Mingyu and Zhang, Xuezhou
author:
- given: Mingyu
  family: Chen
- given: Xuezhou
  family: Zhang
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/chen24d/chen24d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
