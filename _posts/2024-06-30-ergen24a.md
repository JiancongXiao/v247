---
title: Topological Expressivity of ReLU Neural Networks
section: Original Papers
abstract: We study the expressivity of ReLU neural networks in the setting of a binary
  classification problem from a topological perspective. Recently, empirical studies
  showed that neural networks operate by changing topology, transforming a topologically
  complicated data set into a topologically simpler one as it passes through the layers.
  This topological simplification has been measured by Betti numbers, which are algebraic
  invariants of a topological space. We use the same measure to establish lower and
  upper bounds on the topological simplification a ReLU neural network can achieve
  with a given architecture. We therefore contribute to a better understanding of
  the expressivity of ReLU neural networks in the context of binary classification
  problems by shedding light on their ability to capture the underlying topological
  structure of the data. In particular the results show that deep ReLU neural networks
  are exponentially more powerful than shallow ones in terms of topological simplification.
  This provides a mathematically rigorous explanation why deeper networks are better
  equipped to handle complex and topologically rich data sets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ergen24a
month: 0
tex_title: Topological Expressivity of ReLU Neural Networks
firstpage: 1599
lastpage: 1642
page: 1599-1642
order: 1599
cycles: false
bibtex_author: Ergen, Ekin and Grillo, Moritz
author:
- given: Ekin
  family: Ergen
- given: Moritz
  family: Grillo
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/ergen24a/ergen24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
