---
title: Exact Mean Square Linear Stability Analysis for SGD
section: Original Papers
abstract: The dynamical stability of optimization methods at the vicinity of minima
  of the loss has recently attracted significant attention. For gradient descent (GD),
  stable convergence is possible only to minima that are sufficiently flat w.r.t.
  the step size, and those have been linked with favorable properties of the trained
  model. However, while the stability threshold of GD is well-known, to date, no explicit
  expression has been derived for the exact threshold of stochastic GD (SGD). In this
  paper, we derive such a closed-form expression. Specifically, we provide an explicit
  condition on the step size that is both necessary and sufficient for the linear
  stability of SGD in the mean square sense. Our analysis sheds light on the precise
  role of the batch size B. In particular, we show that the stability threshold is
  monotonically non-decreasing in the batch size, which means that reducing the batch
  size can only decrease stability. Furthermore, we show that SGD’s stability threshold
  is equivalent to that of a mixture process which takes in each iteration a full
  batch gradient step w.p. 1-p, and a single sample gradient step w.p. $p$, where
  $p \approx 1/B$. This indicates that even with moderate batch sizes, SGD’s stability
  threshold is very close to that of GD’s. We also prove simple necessary conditions
  for linear stability, which depend on the batch size, and are easier to compute
  than the precise threshold. Finally, we derive the asymptotic covariance of the
  dynamics around the minimum, and discuss its dependence on the learning rate. We
  validate our theoretical findings through experiments on the MNIST dataset.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mulayoff24a
month: 0
tex_title: Exact Mean Square Linear Stability Analysis for SGD
firstpage: 3915
lastpage: 3969
page: 3915-3969
order: 3915
cycles: false
bibtex_author: Mulayoff, Rotem and Michaeli, Tomer
author:
- given: Rotem
  family: Mulayoff
- given: Tomer
  family: Michaeli
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/mulayoff24a/mulayoff24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
